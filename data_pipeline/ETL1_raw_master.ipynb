{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd     \n",
    "import numpy as np \n",
    "from tabulate import tabulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist23 = pd.read_excel(\"./initial_data/2023.xlsx\")\n",
    "hist22 = pd.read_excel(\"./initial_data/2022.xlsx\")\n",
    "litros_board = pd.read_excel(\"./initial_data/litros_board_22_23.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Raw Data \n",
    "\n",
    "Primer intentarem obtenir una sensació de quines columnes contenen les dades històriques i veure si hi ha alguna diferència entre les de 2022 i 2023. Normalitzarem els noms de les columnes i els formats dels valors per unificar els dos històrics en un de uniforme."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_columns = hist22.columns.intersection(hist23.columns)\n",
    "\n",
    "print(\"Common Columns:\", common_columns)\n",
    "\n",
    "# Find columns that are in df1 but not in df2\n",
    "only_22 = hist22.columns.difference(hist23.columns)\n",
    "print(\"Columns only in historic22:\", only_22)\n",
    "\n",
    "# Find columns that are in df2 but not in df1\n",
    "only_23 = hist23.columns.difference(hist22.columns)\n",
    "print(\"Columns only in historic23:\", only_23)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Com bé es pot veure, totes les dades historiques semblen tenir les mateixes columnes i algunes es repeteixen, com Nombre 1 o bé UM. L'historic de 23 te una columna esmentada Número de deudor, la qual es probablement per identificar qui paga la comanda d'aquell bar. Evidentment això no ens es rellevant a nosaltres, aixi que per sinmplificar les coses podriem simplement esborrar per aixi assegurarnos que hi ha les mateixes columnes, a pesar de que s'hauran de normalitzar els valors de totes les columnes perque concordin els 2 historics. A més a més Numero1.1 es el identificador fiscal del bar en concret, pero com estem pre-processant la taula mestre cruda, intentarem deixar el màxim de columnes. També podem esborrar la columna \"Tick sin ped\" ja que aquesta només conté valors nuls i no aporta cap informació rellevant de totes maneres. Les columnes UM , \"N Lote Bolsa\" i tota la informació rellevant al document i quan es va crear/modificar el ticket (Es informació logisitica que no ens es útil)\n",
    "\n",
    "El identificador de barril tampoc ens serveix ja que les dades son incongruents, esborrarem la columna sencera."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist23[\"Tick sin ped\"].count() \n",
    "hist22[\"Tick sin ped\"].count() \n",
    "#Only 5 values are not NaN , therefore this column is a bit useless\n",
    "\n",
    "useless_columns = [\"UM\", \"UM.1\", \"Nº Lote Bolsa\", \"Tick sin ped\", \"Creado por\", \"Creado el\", \"Hora\", \"Modif.por\", \"Modif.el\", \"HoraModif\", \"ID doc.\", \"IDContRep\", \"Tipo doc.\", \"Nº Tanque\"]\n",
    "hist22.drop(columns=useless_columns, inplace=True)\n",
    "hist23.drop(columns=useless_columns, inplace=True)\n",
    "hist23.drop(\"Número de deudor\", inplace=True,axis=1)\n",
    "print(hist23)\n",
    "#print(hist23.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Corrupt Entries (Rows)\n",
    "Caldria també esborrar les files o entrades que siguin conflictives, que tinguin molts molts NaN's o nulls que no aportin cap mena d'informació al model. Ens adonem que el historic de 2023 te dos files inservibles i també el historic de 2022 te les dues últimes columnes inservibles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Last 2 rows are full of NaN's and nulls, we can remove those entries\n",
    "#hist23.drop()\n",
    "print(len(hist23))\n",
    "print(len(hist22))\n",
    "hist23 = hist23.drop(hist23.index[-2:])\n",
    "hist22 = hist22.drop(hist22.index[-2:])\n",
    "print(hist23)\n",
    "print(hist22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Les files són numeros de ticket que contenen 1 bar y 1 proveidor que transporta 1 tipus determinat de cervesa d'1 barril en concret. \n",
    "\n",
    "Pero primerament volem identificar les claus primàries de les files, en aquest cas semblen ser el numero de ticket. El numero ticket es per cadascun dels barrils que compren comprovem si els seus valors no es repeteixen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist22.rename(columns={   \n",
    "                          \" Nº Ticket\": \"num_ticket\", \"Centro Carga\": \"centro_carga\", \"Doc.venta\": \"documento_venta\",\n",
    "                          \"Cliente\": \"id_cliente\", \"Nombre 1\": \"desc_cliente\",\"Nombre 1.1\": \"id_fiscal_proveedor\", \"Proveedor\": \"id_proveedor\", \"EdS\": \"empresa_proveedor\",\n",
    "                          \"Albarán\": \"id_albaran\", \"Lote producto\": \"id_lote_producto\", \"Sal.mcia.real\": \"fecha_pedido\",\n",
    "                          \"Fecha Caducidad\": \"fecha_caducidad\", \"Material\": \"id_cerveza\", \"Número de material\": \"desc_cerveza\",\n",
    "                          \"Vehículo\": \"id_vehiculo\", \"  CtdAlbFab\": \"total_litros_transportados\", \" CtdPedVtas\": \"litros_pedidos_cliente\",\n",
    "                          \"Cantidad entrega\": \"litros_dados_cliente\", \"Entrega\": \"id_orden_entrega\",\n",
    "                          \"F.Descarga\": \"fecha_descarga\", \"H.ini.Desc\": \"hora_inicio_descarga\", \"H.fin.Desc\": \"hora_fin_descarga\",\n",
    "                          \"Presión CO2\": \"pression_co2\", \"Temperat.\": \"temperatura\"\n",
    "                       },\n",
    "               inplace=True\n",
    "              )\n",
    "\n",
    "#hist23 the same adding the column \"Nombre1.1\"\n",
    "hist23.rename(columns={   \n",
    "                          \" Nº Ticket\": \"num_ticket\", \"Centro Carga\": \"centro_carga\", \"Doc.venta\": \"documento_venta\",\n",
    "                          \"Cliente\": \"id_cliente\", \"Nombre 1\": \"desc_cliente\",\"Nombre 1.1\": \"id_fiscal_proveedor\",  \"Proveedor\": \"id_proveedor\", \"EdS\": \"empresa_proveedor\",\n",
    "                          \"Albarán\": \"id_albaran\", \"Lote producto\": \"id_lote_producto\", \"Sal.mcia.real\": \"fecha_pedido\",\n",
    "                          \"Fecha Caducidad\": \"fecha_caducidad\", \"Material\": \"id_cerveza\", \"Número de material\": \"desc_cerveza\",\n",
    "                          \"Vehículo\": \"id_vehiculo\", \"  CtdAlbFab\": \"total_litros_transportados\", \" CtdPedVtas\": \"litros_pedidos_cliente\",\n",
    "                          \"Cantidad entrega\": \"litros_dados_cliente\", \"Entrega\": \"id_orden_entrega\",\n",
    "                          \"F.Descarga\": \"fecha_descarga\", \"H.ini.Desc\": \"hora_inicio_descarga\", \"H.fin.Desc\": \"hora_fin_descarga\",\n",
    "                          \"Presión CO2\": \"pression_co2\", \"Temperat.\": \"temperatura\"\n",
    "                       },\n",
    "               inplace=True\n",
    "              )\n",
    "\n",
    "#h\n",
    "mergeable_hist23 = hist23.drop(columns=[\"id_fiscal_proveedor\"])\n",
    "print(tabulate(hist23, headers=\"keys\", tablefmt=\"psql\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tabulate(hist22, headers=\"keys\", tablefmt=\"psql\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Raw Master & column analysis\n",
    "En aquest apartat crearem una taula mestra que guardarem en un fitxer de format .parquet , ja que aquest a diferencia d'excel o CSV, preserva l'informació dels tipus i noms de les columnes i altres metadates. Fusionarem els històrics de 2022 i 2023. Primerament analitzarem totes les columnes per assegurarnos de la qualitat de les dades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"first ticket {hist22['num_ticket'].min()}, last ticket {hist22['num_ticket'].max()}\")\n",
    "print(f\"first ticket {hist23['num_ticket'].min()}, last ticket {hist23['num_ticket'].max()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Re-cast Data Types \n",
    "Abans de poder guardar les taules en fitxers permanents, haurem de cambiar els tipus a tipus bàsics com strings, enters i altres. Caldrà tractar els valors nuls de dues columnes que no permeten la conversió a tipus int (degut a NaN's i infinits) i usar regex a la columna de temperatura per evitar que les comes ', ens impedeixen la lectura a floats de la temperatura."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(hist22.dtypes)\n",
    "\n",
    "hist22[\"documento_venta\"] = hist22[\"documento_venta\"].fillna(0).astype(int)\n",
    "hist22[\"id_orden_entrega\"] = hist22[\"id_orden_entrega\"].fillna(0).astype(int)\n",
    "hist22[\"temperatura\"] = hist22[\"temperatura\"].replace(\"'\", \".\", regex=True)\n",
    "\n",
    "hist23[\"documento_venta\"] = hist23[\"documento_venta\"].fillna(0).astype(int)\n",
    "hist23[\"id_orden_entrega\"] = hist23[\"id_orden_entrega\"].fillna(0).astype(int)\n",
    "hist23[\"temperatura\"] = hist23[\"temperatura\"].replace(\"'\", \".\", regex=True)\n",
    "\n",
    "\n",
    "\n",
    "type_coertion_dict = {\n",
    "    \"num_ticket\": int,\n",
    "    \"centro_carga\": int,\n",
    "    \"documento_venta\": int,\n",
    "    \"id_cliente\": int, \n",
    "    \"desc_cliente\": str,\n",
    "    \"id_proveedor\": int,\n",
    "    \"id_fiscal_proveedor\": str,\n",
    "    \"empresa_proveedor\": str,\n",
    "    \"id_albaran\": int,\n",
    "    \"id_lote_producto\": str,\n",
    "    \"fecha_pedido\": str,\n",
    "    \"fecha_caducidad\": str,\n",
    "    \"id_cerveza\": str,\n",
    "    \"desc_cerveza\": str, \n",
    "    \"id_vehiculo\": str,\n",
    "    \"id_orden_entrega\": int,\n",
    "    \"fecha_descarga\": str,\n",
    "    \"hora_inicio_descarga\": str,\n",
    "    \"hora_fin_descarga\": str,\n",
    "    \"temperatura\": float\n",
    "}\n",
    "hist22 = hist22.astype(type_coertion_dict)\n",
    "hist23 = hist23.astype(type_coertion_dict)\n",
    "#print(hist23.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist22.to_parquet(\"./processed_data/1_raw_historical_2022.parquet\", index=True)\n",
    "#print(hist22.dtypes)\n",
    "hist23.to_parquet(\"./processed_data/1_raw_historical_2023.parquet\", index=True)\n",
    "\n",
    "master_historical = pd.concat([hist22, hist23], ignore_index=True, sort=True)\n",
    "print(tabulate(master_historical, headers=\"keys\", tablefmt=\"psql\"))\n",
    "#print(master_historical[\"num_ticket\"].describe())\n",
    "master_historical.to_parquet(\"./processed_data/1_raw_master.parquet\",index=True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
